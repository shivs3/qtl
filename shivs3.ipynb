{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from skimage.transform import resize\n",
    "import tensorflow.keras.backend as K\n",
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "# from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Available GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Available GPU devices:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Define Custom Metrics\n",
    "# -------------------------------\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Calculates the Dice Coefficient.\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou_metric(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) metric.\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 57195\n",
      "Training samples: 45756\n",
      "Validation samples: 11439\n"
     ]
    }
   ],
   "source": [
    "# Define the data directory (adjust this path if necessary)\n",
    "data_dir = 'brats2020/content/data'\n",
    "\n",
    "# Get list of .h5 files\n",
    "h5_files = [f for f in os.listdir(data_dir) if f.endswith('.h5')]\n",
    "\n",
    "# Ensure that there are .h5 files in the directory\n",
    "if not h5_files:\n",
    "    raise FileNotFoundError(f\"No .h5 files found in the directory: {data_dir}\")\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_files, val_files = train_test_split(h5_files, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Total samples: {len(h5_files)}\")\n",
    "print(f\"Training samples: {len(train_files)}\")\n",
    "print(f\"Validation samples: {len(val_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 8  # Adjust based on GPU memory\n",
    "image_dim = (128, 128)  # Adjust based on your image dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 5. Define the Data Generator\n",
    "# -------------------------------\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, h5_files, data_dir, batch_size=16, dim=(128, 128), shuffle=True):\n",
    "        self.h5_files = h5_files\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.h5_files))\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.h5_files) / self.batch_size))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        h5_batch = [self.h5_files[k] for k in batch_indexes]\n",
    "        X, y = self.__data_generation(h5_batch)\n",
    "        return X, y\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        \n",
    "    def __data_generation(self, h5_batch):\n",
    "        # Initialize arrays\n",
    "        X = np.empty((self.batch_size, *self.dim, 4), dtype='float32')  # 4 channels\n",
    "        y = np.empty((self.batch_size, *self.dim, 1), dtype='float32')  # Single-channel masks\n",
    "            \n",
    "        for i, h5_file in enumerate(h5_batch):\n",
    "            file_path = os.path.join(self.data_dir, h5_file)\n",
    "            with h5py.File(file_path, 'r') as hf:\n",
    "                # Check for the correct keys\n",
    "                if 'image' in hf.keys() and 'mask' in hf.keys():\n",
    "                    image = hf['image'][:]  # Expected shape: (H, W, 4)\n",
    "                    mask = hf['mask'][:]    # Expected shape: (H, W) or (H, W, C)\n",
    "                else:\n",
    "                    raise KeyError(f\"Unexpected keys in {h5_file}: {list(hf.keys())}\")\n",
    "\n",
    "                # If mask has multiple channels, convert to single-channel\n",
    "                if mask.ndim > 2:\n",
    "                    mask = np.mean(mask, axis=-1)  # Example: Convert RGB to grayscale\n",
    "\n",
    "                # Resize images if necessary\n",
    "                if image.shape[:2] != self.dim:\n",
    "                    image = resize(\n",
    "                        image, \n",
    "                        (*self.dim, image.shape[2]), \n",
    "                        preserve_range=True, \n",
    "                        anti_aliasing=True\n",
    "                    )\n",
    "                \n",
    "                if mask.shape != self.dim:\n",
    "                    # Use nearest-neighbor interpolation for masks to preserve labels\n",
    "                    mask = resize(\n",
    "                        mask, \n",
    "                        self.dim, \n",
    "                        preserve_range=True, \n",
    "                        order=0, \n",
    "                        anti_aliasing=False\n",
    "                    )\n",
    "\n",
    "                # Normalize the image\n",
    "                image_max = np.max(image)\n",
    "                if image_max > 0:\n",
    "                    image = image.astype('float32') / image_max\n",
    "                else:\n",
    "                    image = image.astype('float32')\n",
    "\n",
    "                # Normalize the mask\n",
    "                mask_max = np.max(mask)\n",
    "                if mask_max > 0:\n",
    "                    mask = mask.astype('float32') / mask_max\n",
    "                else:\n",
    "                    mask = mask.astype('float32')  # All zeros\n",
    "\n",
    "                # Assign to batch arrays\n",
    "                X[i] = image  # Shape: (128, 128, 4)\n",
    "                y[i] = np.expand_dims(mask, axis=-1)  # Shape: (128, 128, 1)\n",
    "            \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Instantiate Data Generators\n",
    "# -------------------------------\n",
    "training_generator = DataGenerator(train_files, data_dir, batch_size=batch_size, dim=image_dim, shuffle=True)\n",
    "validation_generator = DataGenerator(val_files, data_dir, batch_size=batch_size, dim=image_dim, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Define Callbacks\n",
    "# -------------------------------\n",
    "# Create a timestamp for the logs\n",
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "# TensorBoard callback for visualization\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# EarlyStopping callback with multiple metric monitoring\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint callback to save the best model with '.keras' extension\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'model-unet.best.h5',  # Changed from '.h5' to '.keras'\n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Combine all callbacks\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    model_checkpoint,\n",
    "    tensorboard_callback\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pennylane in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (0.38.0)\n",
      "Requirement already satisfied: networkx in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (3.2.1)\n",
      "Requirement already satisfied: requests in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (2.32.3)\n",
      "Requirement already satisfied: toml in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (0.10.2)\n",
      "Requirement already satisfied: cachetools in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (5.5.1)\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (0.16.0)\n",
      "Requirement already satisfied: packaging in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (24.2)\n",
      "Requirement already satisfied: autograd in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (1.7.0)\n",
      "Requirement already satisfied: autoray>=0.6.11 in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (0.7.0)\n",
      "Requirement already satisfied: pennylane-lightning>=0.38 in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (0.38.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (4.5.0)\n",
      "Requirement already satisfied: numpy<2.0 in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (1.13.1)\n",
      "Requirement already satisfied: appdirs in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from pennylane) (1.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from requests->pennylane) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from requests->pennylane) (2024.12.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from requests->pennylane) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages (from requests->pennylane) (3.4.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/shivshankar/Desktop/Thesis MSCSK/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 12:41:24.919400: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-03-20 12:41:24.919485: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-03-20 12:41:24.919522: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-03-20 12:41:24.920236: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-03-20 12:41:24.920649: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function validate_device_wires at 0x30faba5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute '_fields'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function validate_device_wires at 0x30faba5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute '_fields'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function validate_measurements at 0x30faba940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid value for \"node\": expected \"ast.AST\", got \"<class 'NoneType'>\"; to visit lists of nodes, use \"visit_block\" instead\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function validate_measurements at 0x30faba940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid value for \"node\": expected \"ast.AST\", got \"<class 'NoneType'>\"; to visit lists of nodes, use \"visit_block\" instead\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _gcd_import at 0x104d30310> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function _gcd_import at 0x104d30310>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _gcd_import at 0x104d30310> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function _gcd_import at 0x104d30310>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _c3_mro at 0x104f13040> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _c3_mro at 0x104f13040> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 4)]        0         []                            \n",
      "                                                                                                  \n",
      " VGG16_Modified (Functional  (None, 4, 4, 512)            1471526   ['input_1[0][0]']             \n",
      " )                                                        4                                       \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 512)                  0         ['VGG16_Modified[0][0]']      \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " quantum_layer (QuantumLaye  (None, 4)                    2052      ['global_average_pooling2d[0][\n",
      " r)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 1, 4)              0         ['quantum_layer[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 1, 1, 256)            1280      ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 8, 8, 512)            0         ['VGG16_Modified[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 4, 4, 256)            0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 256)            1179904   ['up_sampling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 8, 8, 256)            0         ['up_sampling2d[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 8, 8, 512)            0         ['conv2d_1[0][0]',            \n",
      "                                                                     'up_sampling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 16, 16, 512)          0         ['concatenate[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)          589952    ['up_sampling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_2[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 64)           73792     ['up_sampling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 32)           18464     ['up_sampling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSamplin  (None, 128, 128, 32)         0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 1)          33        ['up_sampling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16580741 (63.25 MB)\n",
      "Trainable params: 16580741 (63.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Concatenate, GlobalAveragePooling2D, Dense, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Quantum Circuit\n",
    "n_qubits = 4  \n",
    "n_layers = 2  \n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"tf\")\n",
    "def quantum_circuit(inputs):\n",
    "    \"\"\"Quantum circuit processing inputs\"\"\"\n",
    "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    for _ in range(n_layers):\n",
    "        qml.templates.BasicEntanglerLayers(weights=np.random.randn(n_layers, n_qubits), wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "# Custom Keras Quantum Layer\n",
    "class QuantumLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim=n_qubits, **kwargs):\n",
    "        super(QuantumLayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.dense = Dense(n_qubits, activation=\"tanh\")  \n",
    "\n",
    "    def call(self, inputs):\n",
    "        reduced_inputs = self.dense(inputs)  # Ensuring the correct input shape\n",
    "        outputs = tf.vectorized_map(lambda x: quantum_circuit(x), reduced_inputs)\n",
    "        return tf.reshape(outputs, (-1, self.output_dim))  # Ensuring correct batch output shape\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "# Function to Modify VGG16 for 4-channel Input\n",
    "def get_vgg16_encoder(input_shape=(128, 128, 4)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv1\")(inputs)\n",
    "    \n",
    "    # Load pretrained VGG16 with a 3-channel input to extract weights\n",
    "    vgg16 = tf.keras.applications.VGG16(include_top=False, weights=\"imagenet\", input_shape=(128, 128, 3))\n",
    "    \n",
    "    for i in range(2, len(vgg16.layers)):  # Skip input and first Conv2D layer\n",
    "        x = vgg16.layers[i](x)\n",
    "\n",
    "    return Model(inputs, x, name=\"VGG16_Modified\")\n",
    "\n",
    "# U-Net Model with VGG16 Encoder + Quantum Circuit\n",
    "def build_quantum_unet(input_shape=(128, 128, 4)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # VGG16 Encoder (Pretrained, Modified)\n",
    "    base_model = get_vgg16_encoder(input_shape)\n",
    "    encoder_output = base_model(inputs)  # Last convolutional layer (4x4x512)\n",
    "\n",
    "    # Quantum Layer at Bottleneck\n",
    "    q_input = GlobalAveragePooling2D()(encoder_output)  # Reduce spatial dims to (512,)\n",
    "    q_output = QuantumLayer()(q_input)  # Quantum Processing (4,)\n",
    "\n",
    "    # Reshape quantum output to match CNN feature maps\n",
    "    # Ensure quantum output has correct dimensions before reshaping\n",
    "    q_feature_map = Reshape((1, 1, n_qubits))(q_output)  # Output shape: (batch_size, 1, 1, 4)\n",
    "    q_feature_map = Conv2D(256, (1, 1), activation=\"relu\", padding=\"same\")(q_feature_map)  # Match channels\n",
    "    q_feature_map = UpSampling2D((4, 4))(q_feature_map)  # Resize to (4x4,256)\n",
    "\n",
    "    # Decoder (U-Net)\n",
    "    x = UpSampling2D((2, 2))(encoder_output)  # Upsample to (8x8,512)\n",
    "    x = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    # Ensure shape match before concatenation\n",
    "    q_feature_map = UpSampling2D((2, 2))(q_feature_map)  # Resize to (8x8,256)\n",
    "    \n",
    "    x = Concatenate()([x, q_feature_map])  # Now shapes match (8x8,512)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)  # Upsample to (16x16)\n",
    "    x = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)  # Upsample to (32x32)\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)  # Upsample to (64x64)\n",
    "    x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)  # Upsample to (128x128)\n",
    "    outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Build and check the model\n",
    "model = build_quantum_unet()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 4)]        0         []                            \n",
      "                                                                                                  \n",
      " VGG16_Modified (Functional  (None, 4, 4, 512)            1471526   ['input_1[0][0]']             \n",
      " )                                                        4                                       \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 512)                  0         ['VGG16_Modified[0][0]']      \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " quantum_layer (QuantumLaye  (None, 4)                    2052      ['global_average_pooling2d[0][\n",
      " r)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 1, 4)              0         ['quantum_layer[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 1, 1, 256)            1280      ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 8, 8, 512)            0         ['VGG16_Modified[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 4, 4, 256)            0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 256)            1179904   ['up_sampling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 8, 8, 256)            0         ['up_sampling2d[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 8, 8, 512)            0         ['conv2d_1[0][0]',            \n",
      "                                                                     'up_sampling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 16, 16, 512)          0         ['concatenate[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)          589952    ['up_sampling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_2[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 64)           73792     ['up_sampling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 32)           18464     ['up_sampling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSamplin  (None, 128, 128, 32)         0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 1)          33        ['up_sampling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16580741 (63.25 MB)\n",
      "Trainable params: 16580741 (63.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', dice_coefficient, iou_metric])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "2025-03-20 12:41:55.654703: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5719/5719 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9944 - dice_coefficient: 0.5781 - iou_metric: 0.4295      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:05:41.108097: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.01034, saving model to model-unet.best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivshankar/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5719/5719 [==============================] - 1596s 278ms/step - loss: 0.0153 - accuracy: 0.9944 - dice_coefficient: 0.5781 - iou_metric: 0.4295 - val_loss: 0.0103 - val_accuracy: 0.9960 - val_dice_coefficient: 0.6839 - val_iou_metric: 0.5375\n"
     ]
    }
   ],
   "source": [
    "epochs = 1 # You can adjust this based on your requirements\n",
    "\n",
    "try:\n",
    "    results = model.fit(\n",
    "        training_generator,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1  # Set to 1 for progress bar, 2 for one line per epoch, 0 for silent\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved as 'final_model_unet.keras'.\n"
     ]
    }
   ],
   "source": [
    "model.save('final_model_unet.keras')\n",
    "print(\"Model training complete and saved as 'final_model_unet.keras'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved as 'training_history.json'.\n",
      "Loss plot saved as 'loss_plot.png'.\n",
      "Accuracy plot saved as 'accuracy_plot.png'.\n",
      "Dice_coefficient plot saved as 'dice_coefficient_plot.png'.\n",
      "Iou_metric plot saved as 'iou_metric_plot.png'.\n"
     ]
    }
   ],
   "source": [
    "with open('training_history.json', 'w') as f:\n",
    "    json.dump(results.history, f)\n",
    "print(\"Training history saved as 'training_history.json'.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 12. Plot Training History\n",
    "# -------------------------------\n",
    "def plot_training_history(history, metrics=['loss', 'accuracy', 'dice_coefficient', 'iou_metric']):\n",
    "    \"\"\"\n",
    "    Plots training and validation metrics over epochs.\n",
    "    \"\"\"\n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(history[metric], label=f'Training {metric}')\n",
    "        plt.plot(history[f'val_{metric}'], label=f'Validation {metric}')\n",
    "        plt.title(f'Training and Validation {metric.capitalize()}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'{metric}_plot.png')\n",
    "        plt.close()\n",
    "        print(f\"{metric.capitalize()} plot saved as '{metric}_plot.png'.\")\n",
    "\n",
    "# Plot and save the training history\n",
    "plot_training_history(results.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing predictions on the validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 13:39:10.259312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "Visualization for sample 1 saved as 'sample_visualization_1.png'\n",
      "Visualization for sample 2 saved as 'sample_visualization_2.png'\n",
      "Visualization for sample 3 saved as 'sample_visualization_3.png'\n",
      "Visualization for sample 4 saved as 'sample_visualization_4.png'\n",
      "Visualization for sample 5 saved as 'sample_visualization_5.png'\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 14. Visualize Results\n",
    "# -------------------------------\n",
    "def visualize_predictions(generator, model, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualizes predictions of the model on a few samples.\n",
    "    \"\"\"\n",
    "    samples_visualized = 0\n",
    "    for X_batch, y_true_batch in generator:\n",
    "        # Predict the batch\n",
    "        y_pred_batch = model.predict(X_batch)\n",
    "        \n",
    "        for i in range(len(X_batch)):\n",
    "            if samples_visualized >= num_samples:\n",
    "                return  # Stop after visualizing the requested number of samples\n",
    "            \n",
    "            input_image = X_batch[i]\n",
    "            true_mask = y_true_batch[i].squeeze()  # Remove single channel\n",
    "            pred_mask = y_pred_batch[i].squeeze()  # Remove single channel\n",
    "            \n",
    "            # Plot input image, true mask, and predicted mask\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # Original Input Image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(input_image[..., 0], cmap='gray')  # Show only one channel\n",
    "            plt.title('Input Image (Channel 0)')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # True Mask\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(true_mask, cmap='gray')\n",
    "            plt.title('True Mask')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Predicted Mask\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(pred_mask, cmap='gray')\n",
    "            plt.title('Predicted Mask')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Save or show the plot\n",
    "            plt.savefig(f'sample_visualization_{samples_visualized + 1}.png')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Visualization for sample {samples_visualized + 1} saved as 'sample_visualization_{samples_visualized + 1}.png'\")\n",
    "            samples_visualized += 1\n",
    "\n",
    "# Visualize predictions on the validation set\n",
    "print(\"Visualizing predictions on the validation set...\")\n",
    "visualize_predictions(validation_generator, model, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model_unet.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the model with custom objects\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdice_coefficient\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8234\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miou_metric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7008\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages/keras/src/saving/saving_api.py:230\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    239\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:275\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    272\u001b[0m             asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:240\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 240\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n",
      "File \u001b[0;32m~/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages/keras/src/saving/serialization_lib.py:704\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m safe_mode_scope \u001b[38;5;241m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[0;32m--> 704\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m build_config:\n",
      "File \u001b[0;32m~/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages/keras/src/engine/training.py:3227\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3219\u001b[0m revivable_as_functional \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3220\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {functional\u001b[38;5;241m.\u001b[39mFunctional, Model}\n\u001b[1;32m   3221\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m functional_init_args\n\u001b[1;32m   3222\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (argspec\u001b[38;5;241m.\u001b[39mvarargs \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39mvarkw \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3223\u001b[0m )\n\u001b[1;32m   3224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m   3225\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m   3226\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[0;32m-> 3227\u001b[0m     inputs, outputs, layers \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m   3229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3230\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m   3231\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs, name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3232\u001b[0m     )\n\u001b[1;32m   3233\u001b[0m     functional\u001b[38;5;241m.\u001b[39mconnect_ancillary_layers(model, layers)\n",
      "File \u001b[0;32m~/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages/keras/src/engine/functional.py:1502\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m layer_nodes:\n\u001b[1;32m   1501\u001b[0m     node_data \u001b[38;5;241m=\u001b[39m layer_nodes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1503\u001b[0m         layer_nodes\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1505\u001b[0m         \u001b[38;5;66;03m# If a node can't be processed, stop processing the\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m         \u001b[38;5;66;03m# nodes of the current layer to maintain node ordering.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Thesis MSCSK/venv/lib/python3.9/site-packages/keras/src/engine/functional.py:1442\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_preserve_input_structure_in_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m_preserve_input_structure_in_config\n\u001b[1;32m   1438\u001b[0m ):\n\u001b[1;32m   1439\u001b[0m     input_tensors \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39munnest_if_single_tensor(\n\u001b[1;32m   1440\u001b[0m         input_tensors\n\u001b[1;32m   1441\u001b[0m     )\n\u001b[0;32m-> 1442\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;66;03m# Update node index map.\u001b[39;00m\n\u001b[1;32m   1445\u001b[0m output_index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output_tensors)[\n\u001b[1;32m   1446\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1447\u001b[0m ]\u001b[38;5;241m.\u001b[39m_keras_history\u001b[38;5;241m.\u001b[39mnode_index\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define the file path (adjust if necessary)\n",
    "model_path = 'final_model_unet.keras'\n",
    "\n",
    "# Load the model with custom objects\n",
    "model = load_model(model_path, custom_objects={\n",
    "    'dice_coefficient': 0.8234,\n",
    "    'iou_metric': 0.7008\n",
    "})\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(file_path, image_dim=(128, 128)):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses an image and its corresponding mask from an h5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        # Check for 'image' and 'mask' keys\n",
    "        if 'image' in hf.keys() and 'mask' in hf.keys():\n",
    "            image = hf['image'][:]  # Shape: (H, W, 4)\n",
    "            mask = hf['mask'][:]    # Shape: (H, W)\n",
    "        else:\n",
    "            raise KeyError(f\"Unexpected keys in {file_path}: {list(hf.keys())}\")\n",
    "\n",
    "        # Print mask statistics for debugging\n",
    "        print(f\"Mask stats for {file_path}: min={mask.min()}, max={mask.max()}, mean={mask.mean()}\")\n",
    "\n",
    "        # Resize the image and mask to match the model's input dimensions\n",
    "        if image.shape[:2] != image_dim:\n",
    "            image = resize(image, (*image_dim, image.shape[2]), preserve_range=True, anti_aliasing=True)\n",
    "        if mask.shape[:2] != image_dim:\n",
    "            mask = resize(mask, image_dim, preserve_range=True, order=0, anti_aliasing=False)\n",
    "\n",
    "        # Normalize the image\n",
    "        image_max = np.max(image)\n",
    "        if image_max > 0:\n",
    "            image = image.astype('float32') / image_max\n",
    "\n",
    "        # Normalize the mask to range [0, 1] for visualization\n",
    "        mask = np.expand_dims((mask - mask.min()) / (mask.max() - mask.min() + 1e-8), axis=-1)\n",
    "\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask stats for brats2020/content/data/volume_106_slice_100.h5: min=0, max=1, mean=0.014253472222222223\n",
      "1/1 [==============================] - 0s 258ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "# -------------------------------\n",
    "# Visualize Predictions\n",
    "# -------------------------------\n",
    "def predict_and_visualize(file_paths, model, image_dim=(128, 128)):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses images from file paths, predicts their outputs, and visualizes results.\n",
    "    \"\"\"\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        # Load and preprocess the image and mask\n",
    "        image, true_mask = preprocess_image(file_path, image_dim)\n",
    "\n",
    "        # Predict the mask using the model\n",
    "        pred_mask = model.predict(np.expand_dims(image, axis=0))[0]  # Add batch dimension, then remove it\n",
    "\n",
    "        # Visualize the input image, true mask, and predicted mask\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Original Input Image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image[..., 0], cmap='gray')  # Display the first channel\n",
    "        plt.title('Input Image (Channel 0)')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # True Mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(true_mask.squeeze(), cmap='gray')  # Remove the channel dimension for display\n",
    "        plt.title('True Mask')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Predicted Mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_mask.squeeze(), cmap='gray')  # Remove the channel dimension for display\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Show the plot directly\n",
    "        plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# Specify the File Paths\n",
    "# -------------------------------\n",
    "data_dir = 'brats2020/content/data'\n",
    "files_to_predict = [\n",
    "    \"brats2020/content/data/volume_106_slice_100.h5\"\n",
    "    \n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# Predict and Visualize\n",
    "# -------------------------------\n",
    "predict_and_visualize(files_to_predict, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 723383,
     "sourceId": 1267593,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
